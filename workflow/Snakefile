'''Snakefile for MIS preparation
   Version 1.0'''

import re
import glob
import os

configfile: 'config/config.yaml'
shell.executable('/bin/bash')

# --- Process chromosomes config ---

def parse_chrom(chrs):
    clist = [x.split(":") for x in chrs.split(",")]
    parsed = []
    for chrs in clist:
        if len(chrs) == 2:
            chrs = [str(c) for c in range(int(chrs[0]), int(chrs[1]) + 1)]
        elif len(chrs) != 1:
            raise ValueError("Invalid chromosome list.")
        parsed += chrs
    return parsed


if 'chr' in config:
    raise ValueError(
        "Outdated CHR sepec in config. Please use chroms: 'from:to,other'")
elif 'chrom' not in config:
    CHROM = parse_chrom('1:22')
else:
    CHROM = parse_chrom(config['chroms'])

# --- Process input files from config ---

INPATH = os.path.normpath(config['directory'])

if 'COHORT' in config and config['COHORT']:
    COHORT = config["COHORT"]
else:
    # Get list of all .bed files
    # Sample is every base name for the .bed files in the INPATH directory
    expression = re.compile(r"(^.*\/)(.*)(?=\.bed)")
    COHORT = [expression.search(x)[2] for x in glob.iglob(INPATH + "/*.bed")]

# --- Process keep and remove ---


def sampfilt(config):
    def filtstr(x):
        if not (x in config and config[x] and config[x] is not None):
            return None
        elif os.path.isfile(config[x]):
            paramstr = 'keep' if x == 'include_samp' else 'remove'
            return '--{} {}'.format(paramstr, os.path.normpath(config[x]))
        else:
            filt = 'inclusion' if x == 'include_samp' else 'exclusion'
            raise Exception("Invalid {} list: {}.".format(filt, config[x]))
    x = [filtstr(x) for x in ['include_samp', 'exclude_samp']]
    x = [i for i in x if i is not None]
    return ' '.join(x) if x else ''


keep_remove_command = sampfilt(config)

# --- Process imputation settings ---

imputation_defaults = {
    'nih': {
        'server': 'NIH',
        'refpanel': 'topmed-r2',
        'population': 'all'},
    'michigan': {
        'server': 'Michigan',
        'refpanel': 'hrc-r1.1',
        'population': 'mixed'}}

if 'imputation' in config and 'default' in config['imputation']:
    default_cfg = config['imputation']['default']
    if ( 'server' in default_cfg and default_cfg['server'].lower() == 'michigan'
         or ('refpanel' in default_cfg
             and default_cfg['refpanel'].lower() == 'hrc-r1.1')):
        default_imp = imputation_defaults['michigan']
    elif ('refpanel' in default_cfg and
          default_cfg['refpanel'].lower() == 'topmed-r2'):
        default_imp = imputation_defaults['nih']
    elif ('refpanel' in default_cfg and default_cfg['refpanel']
          and 'server' in default_cfg and default_cfg['server']
          and 'population' in default_cfg and default_cfg['population']):
        default_imp = default_cfg
    else:
        raise ValueError('Must specify at least server or panel')
    default_imp.update(default_cfg)
else:
    default_imp = imputation_defaults['nih']

imp_settings = dict()
server = dict()
token = dict()

for cht in COHORT:
    imp_settings[cht] = default_imp.copy()
    if 'imputation' in config and cht in config['imputation']:
        imp_settings[cht].update(config['imputation'][cht])
    if 'token' in imp_settings[cht]:
        token[cht] = imp_settings[cht].pop('token')
    else:
        raise ValueError("Must provide either cohort or default API token.")
    server[cht] = imp_settings[cht].pop('server')

# --- Done processing ---

BPLINK = ['bed', 'bim', 'fam']
OUTDIR = config["out_dir"]

def flatten(nested):
    flat = []
    for el in nested:
        if not isinstance(el, list):
            flat.append(el)
        else:
            flat += flatten(el)
    return flat


outs = dict(
    stat_report="{impute_dir}/stats/{cohort}_impStats.html",
    vcf_bycohort="{impute_dir}/data/{cohort}_chrall_filtered.vcf.gz",
    vcf_merged="{impute_dir}/data/all_chrall_filtered.vcf.gz",
    bgen_bycohort="{impute_dir}/data/{cohort}_chrall_filtered.bgen",
    bgen_merged="{impute_dir}/data/merged/merged_chrall_filtered.bgen",
    plink_bycohort="{impute_dir}/data/{cohort}_chrall_filtered.{ext}",
    plink_merged="{impute_dir}/data/all_chrall_filtered.{ext}")

def expand_outs(out):
    return expand(out, cohort=COHORT, ext=BPLINK, impute_dir=OUTPATH)

imputed = flatten([expand_outs(outs[x]) for x in config["outputs"]])


if config['check_vcf']:
    rule all:
        input:
            expand('{outdir}/log/{cohort}_chr{chrom}.check.log',
                   cohort=COHORT, chrom=CHROM, outdir=OUTDIR)
else:
    rule all:
        input:
            expand('{outdir}/ready/{cohort}_chr{chrom}.vcf.gz',
                   cohort=COHORT, chrom=CHROM, outdir=OUTDIR),
            imputed

include: 'part1.smk'

if config['chr_callrate']:
    include: 'chr_callrate.smk'
elif config['chunk_callrate']:
    include: 'chunk_callrate.smk'
else:
    rule compress_vcf_nocallrate:
        input: rules.split_to_vcf.output
        output: '{outdir}/ready/{cohort}_chr{chrom}.vcf.gz'
        threads: 4
        resources:
            mem_mb = 8192,
            time_min = 30
        conda: 'envs/bcftools.yaml'
        shell:
            '''
    bcftools sort --threads {threads} -Oz -o {output} {input}
    bcftools index -t {output}
    '''

rule apply_irem:
    input:
        irem = '{outdir}/callrate/{cohort}/chrall.irem',
        vcf = '{outdir}/{cohort}_chr{chrom}_preCallcheck.vcf.gz',
        tbi = '{outdir}/{cohort}_chr{chrom}_preCallcheck.vcf.gz.tbi'
    output: '{outdir}/ready/{cohort}_chr{chrom}.vcf.gz'
    threads: 4
    resources:
        mem_mb = 8192,
        time_min = 30
    conda: 'envs/bcftools.yaml'
    shell:
        '''
bcftools view --threads {threads} -S ^{input.irem} -Oz -o {output} {input.vcf}
bcftools index -t {output}
'''

rule submit_imputation:
    input:
        vcf = expand('{{outdir}}/ready/{{cohort}}_chr{chrom}.vcf.gz',
                     chrom=CHROM),
        contig_build = rules.rename_chrom.output.json
    output: '{outdir}/imputation/{cohort}_imputation.json'
    params:
        server = lambda wc: server[wc['cohort']],
        token = lambda wc: token[wc['cohort']],
        imp_settings = lambda wc: imp_settings[wc['cohort']]
    conda: 'envs/apicall.yaml'
    script: 'scripts/submit_imputation.py'

rule download_imputation:
    input: rules.submit_imputation.output
    output:
        temp(expand('{{outdir}}/imputed/{{cohort}}/chr_{chrom}.zip',
             chrom=CHROM))
    params:
        outdir = '{outdir}/imputed/{cohort}',
        token = rules.submit_imputation.params.token
    conda: 'envs/apicall.yaml'
    script: 'scripts/download_imputation.py'

rule unzip:
    input:
        zip = '{outdir}/imputed/{cohort}/chr_{chrom}.zip',
        json = rules.submit_imputation.output
    output:
        vcf = '{outdir}/imputed/{cohort}/chr{chrom}.dose.vcf.gz',
        info = '{outdir}/imputed/{cohort}/chr{chrom}.info.gz'
    params:
        odir = '{outdir}/imputed/{cohort}',
    conda: 'workflow/envs/p7z.yaml'
    shell: '7za e {input} -p$(jq -r .password {input.json}) -o{params.odir}'

postImpute_config['outputs'] = config['outputs']
postImpute_config['chroms'] = config['chroms']
postImpute_config['directory_in'] = OUTDIR + '/imputed'
postImpute_config['directory_out'] = OUTDIR + '/imputed_processed'
postImpute_config['qc'] = config['postqc']

postImpute_config = 'intermediate/pre-impute_ancestry'

# Post Imputation
module postImpute:
    snakefile: "modules/postImpute/Snakefile"
    config: config["postImpute"]

use rule * from postImpute as postImpute_*
